{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "# Install required binaries and packages\n",
    "#\n",
    "# !apt-get install openslide-tools\n",
    "# !pip install scikit-image opencv-python shapely h5py openslide-python dataclasses pydantic\n",
    "#\n",
    "# We need to clone project and add it to sys.path (we haven't installable packages yet)\n",
    "# Git clone will work after opening access\n",
    "# !git clone git@gitlab.com:Digipathology/dieyepy.git\n",
    "path_to_project = r'D:\\projects\\dieyepy\\src\\main\\python'\n",
    "# path_to_project = 'dieyepy/src/main/python'\n",
    "sys.path.append(str(pathlib.Path(path_to_project).resolve()))\n",
    "\n",
    "# We define working root folder for convenience\n",
    "root_path = pathlib.Path.home().joinpath(\"temp/slice_example1\")\n",
    "root_input_path = root_path.joinpath(\"input\")\n",
    "root_output_path = root_path.joinpath(\"output\")\n",
    "root_input_path.mkdir(parents=True, exist_ok=True)\n",
    "root_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Original mrxs slide is about 4gb memory.\n",
    "# To make example more reproducible and lightweight we cut a small region from it and interpret it as a real slide.\n",
    "# Define paths to slides and annotations\n",
    "slide1_path = str(root_input_path.joinpath(\"slide1.jpeg\").resolve())\n",
    "slide1_annotations_path = str(root_input_path.joinpath(\"slide1_annotations.json\").resolve())\n",
    "slide2_path = str(root_input_path.joinpath(\"slide2.jpeg\").resolve())\n",
    "slide2_annotations_path = str(root_input_path.joinpath(\"slide2_annotations.json\").resolve())\n",
    "\n",
    "# Original big-size slides.\n",
    "# slide1_path = r\"D:\\temp\\slides\\slide1.mrxs\"\n",
    "# slide1_annotations_path = r\"D:\\temp\\slides\\slide1_annotations.json\"\n",
    "# slide2_path = r\"D:\\temp\\slides\\slide5.mrxs\"\n",
    "# slide2_annotations_path = r\"D:\\temp\\slides\\slide5_annotations.json\"\n",
    "def load_images_and_annotations():\n",
    "    if not pathlib.Path(slide1_path).exists():\n",
    "        urlretrieve(\"https://drive.google.com/uc?id=1n8TDA-4gnNSb0fUFhm5i7J5FitfcJVoH\", slide1_path)\n",
    "    if not pathlib.Path(slide1_annotations_path).exists():\n",
    "        urlretrieve(\"https://drive.google.com/uc?id=1He8XhiRTw6zGiVqlYLtqSGeHiI4th1LX\", slide1_annotations_path)\n",
    "    if not pathlib.Path(slide2_path).exists():\n",
    "        urlretrieve(\"https://drive.google.com/uc?id=1BrpN42SZoaz46CjqUQNy2rn5seRBui0w\", slide2_path)\n",
    "    if not pathlib.Path(slide2_annotations_path).exists():\n",
    "        urlretrieve(\"https://drive.google.com/uc?id=1itDFGs83HiGuSGLNV-G1BVJUOuv1LPtO\", slide2_annotations_path)\n",
    "\n",
    "\n",
    "load_images_and_annotations()\n",
    "# There are several use-cases for slicing slide-images.\n",
    "# 1) Generating patch_label_images together with generating patch_slide_images. Where\n",
    "#    a) patch_label_image is a result of drawing annotation with label color stored in annotation\n",
    "#    b) patch_slide_image is just a corresponding region from the same slide\n",
    "# 2) Generate patch_label_images together with generating patch_slide_images. Where\n",
    "#    a) patch_label_image is a region from some specifically stained slide\n",
    "#    b) patch_slide_image is the same region from (possibly a bit shifted) corresponding H&E slide\n",
    "# 3) Do not generate patch_label_images but generate just patch_slide_images.\n",
    "#    It can be useful when you want:\n",
    "#    - label patches manually in some graphics editor\n",
    "#    - label patches with your custom script\n",
    "#\n",
    "# Here we will consider the use-case 1.\n",
    "# We will generate patch_label_images and then generate corresponding patch_slide_images.\n",
    "#\n",
    "# High-level api for generating patches operates on dict-like config objects.\n",
    "# There are 2 types of config: PatchImageSourceConfig, PatchImageConfig.\n",
    "# PatchImageSourceConfig defines params for generating patches from slide.\n",
    "# It is named \"source\" because it initiates data-flow:\n",
    "# patch_pos->patch_geometry->patch_label_image->patch_slide_image.\n",
    "# It is designed so to allow hooks.\n",
    "# Different hooks can be placed in this data-flow such that irrelevant\n",
    "# and uninteresting positions/resulting label images will be filtered out.\n",
    "# At this moment PatchResponseGenerator uses such hooks that\n",
    "# it skips patch geometry if it doesn't fully contained by some roi annotation.\n",
    "# You can add your hooks to this data-flow. For example you can add hook to filter out patch label images\n",
    "# that are uninteresting in sense of class distribution - ignore fully\n",
    "# white or fully black resulting label images but take only label image containing both classes.\n",
    "#\n",
    "# Grid positions and label images can be filtered out in data-flow so\n",
    "# ONLY AFTER generating patch_label_image and confirming it as \"interesting\"(means not filtering it out)\n",
    "# it make sense to generate corresponding patch_slide_image.\n",
    "# It means that process of generating patch_slide_images depends on process\n",
    "# of generating patch_label_images. This dependence is represented with attribute\n",
    "# \"dependents\" in PatchImageSourceConfig.\n",
    "#\n",
    "# The configs defined below specify to:\n",
    "# generate patch_label_images from slide1 based on slide1_annotations\n",
    "# generate corresponding(geometrically) patch_slide_images from slide1\n",
    "# generate patch_label_images from slide2 based on slide2_annotations\n",
    "# generate corresponding(geometrically) patch_slide_images from slide2\n",
    "\n",
    "# patch size in pixels. Resulting patches will have this size\n",
    "patch_size = (512, 512)\n",
    "# level of slide. Can be interpreted as level of detail(resolution) with the best detail at 0-level.\n",
    "level = 0\n",
    "# stride of slicer - distance between subsequent patches\n",
    "stride_x, stride_y = patch_size[0] // 2, patch_size[1] // 2\n",
    "\n",
    "from slice.model.patch_image_config import PatchImageConfig\n",
    "from slice.model.patch_image_source_config import PatchImageSourceConfig\n",
    "\n",
    "configs = [\n",
    "    PatchImageSourceConfig(\n",
    "        slide_path=slide1_path,\n",
    "        level=level,\n",
    "        annotations_path=slide1_annotations_path,\n",
    "        metadata={\"name\": \"label\"},\n",
    "        patch_size=patch_size,\n",
    "        stride_x=stride_x,\n",
    "        stride_y=stride_y,\n",
    "        dependents=[\n",
    "            PatchImageConfig(\n",
    "                slide_path=slide1_path,\n",
    "                level=level,\n",
    "                metadata={\"name\": \"image\"}\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    PatchImageSourceConfig(\n",
    "        slide_path=slide2_path,\n",
    "        level=level,\n",
    "        annotations_path=slide2_annotations_path,\n",
    "        metadata={\"name\": \"label\"},\n",
    "        patch_size=patch_size,\n",
    "        stride_x=stride_x,\n",
    "        stride_y=stride_y,\n",
    "        dependents=[\n",
    "            PatchImageConfig(\n",
    "                slide_path=slide2_path,\n",
    "                level=level,\n",
    "                metadata={\"name\": \"image\"}\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "# PatchResponseGenerator processes configs one by one generating patches and puts these patches into\n",
    "# one data-flow: Iterable[PatchResponse]\n",
    "from slice.generator.response.patch_response_generator import PatchResponseGenerator\n",
    "\n",
    "patch_responses = PatchResponseGenerator().create(configs)\n",
    "\n",
    "# Then we convert every patch_response to named_ndarray - Tuple[str, np.ndarray]\n",
    "# We select name format convenient for saving/loading to/from disk.\n",
    "from slice.patch_response_utils import patch_responses_to_named_ndarrays\n",
    "\n",
    "format_str = r\"{cfg.slide_path}/{cfg.patch_size[0]},{cfg.patch_size[1]}/{cfg.metadata[name]}/{pos[1]},{pos[0]}_{cfg.level}_{cfg.metadata[name]}.png\"\n",
    "named_ndarrays = patch_responses_to_named_ndarrays(patch_responses, format_str)\n",
    "\n",
    "\n",
    "# Lets collect data-flow to list and print some info\n",
    "def print_named_ndarrays_info(named_ndarrays):\n",
    "    print(f\"arrays count: {len(named_ndarrays)}\")\n",
    "    if len(named_ndarrays):\n",
    "        print(f\"1-st array (name,shape): {(named_ndarrays[0][0], named_ndarrays[0][1].shape)}\")\n",
    "\n",
    "\n",
    "named_ndarrays = list(named_ndarrays)\n",
    "print_named_ndarrays_info(named_ndarrays)\n",
    "\n",
    "# We often want to store results of generating patches.\n",
    "# It is convenient to store data hierarchically.\n",
    "# 3 hierarchial data storages are supported:\n",
    "# 1) hdf5 (patches are stored as arrays in a single file)\n",
    "# 2) zip archive (patches are stored as arrays in a single file)\n",
    "# 3) file system folders (patches are stored as image files in folders)\n",
    "#\n",
    "# Single file with arrays VS folders with image files.\n",
    "# Single file with arrays is easier and faster to:\n",
    "# a) manage(delete, copy)\n",
    "# b) transfer and synchronize with remote storage (like google disk which can be used from google colab)\n",
    "# c) use in processing later (for examplle training model with keras)\n",
    "# File system folder with image files is easier to:\n",
    "# a) explore\n",
    "# b) image-compression often is better than zip-compression for arrays\n",
    "#\n",
    "from ndarray_persist.ndarray_persist_utils import save_named_ndarrays\n",
    "\n",
    "data_path = root_output_path.joinpath(\"results\")\n",
    "# data_path = root_output_path.joinpath(\"results.zip\")\n",
    "# data_path = root_output_path.joinpath(\"results.hdf5\")\n",
    "save_named_ndarrays(named_ndarrays, str(data_path), delete_if_exists=True, verbosity=1)\n",
    "\n",
    "# We have just saved both labels and images.\n",
    "# Now we can load both labels and images from data store as one data-flow: load_named_ndarrays(data_path)\n",
    "# But it is common case to load labels and images separately, so here is example.\n",
    "from ndarray_persist.ndarray_persist_utils import load_named_ndarrays\n",
    "\n",
    "named_labels = load_named_ndarrays(str(data_path), name_pattern=f'.*/{patch_size[0]},{patch_size[1]}/label/.*')\n",
    "named_images = load_named_ndarrays(str(data_path), name_pattern=f'.*/{patch_size[0]},{patch_size[1]}/image/.*')\n",
    "named_labels, named_images = list(named_labels), list(named_images)\n",
    "print_named_ndarrays_info(named_labels)\n",
    "print_named_ndarrays_info(named_images)\n",
    "\n",
    "# Lets plot (patch_image, patch_label) pairs\n",
    "from common_matplotlib.core import plot_named_ndarrays_tuples_by_batches\n",
    "\n",
    "image_tuples = zip(named_images, named_labels)\n",
    "plot_named_ndarrays_tuples_by_batches(image_tuples, ncols=10, tuples_per_plot=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dieyepy",
   "language": "python",
   "name": "dieyepy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
